# AI-powered-Action-recognition-using-LSTM
This project presents an innovative solution for real-time action recognition and multilingual translation, leveraging deep learning and computer vision technologies. The system is designed to enhance human-computer interaction by enabling seamless interpretation and communication of human actions across multiple languages.At its core, the system utilizes the MediaPipe framework for real-time landmark detection and tracking, integrated with Long Short-Term Memory (LSTM) neural networks for accurate recognition of a diverse range of human actions. Upon recognizing an action, the system translates it into a pre-defined, contextually meaningful sentence. These sentences are then translated into multiple languages, enabling communication across linguistic barriers.To extend the system’s usability, especially in critical or assistive contexts, it includes a communication feature that allows these translated sentences to be sent as messages via SMS or WhatsApp. The integration with the Twilio API for SMS and the official WhatsApp Business API ensures timely message delivery. This feature significantly enhances the system's practicality in scenarios such as healthcare, emergency response, or accessibility support—where quick, hands-free communication is essential.By combining real-time action recognition, multilingual translation, and immediate communication, this system serves not just as a recognition tool but as a comprehensive, accessible communication aid for users with diverse needs.
